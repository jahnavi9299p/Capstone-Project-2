{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from random import randint\n",
    "import nltk.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  good one course say know blessing curse absolutely positive best friend could amaze couple count yes could madly love case accommodate feeling thank link socaled tisi cringle root current topicobsesion deadly like lodge idea mind roll circle feel truly awful detect curious vegetation expression grass twelve different plant coinage imagine hundred year later whenif dirt smith never one ever frequently discovery staining face marble tileswod yearold sentence incredibly accurate beautiful description visit web_site stopping_point year whoever read possibly evening remember highly doubt sit garden writing song sing together twelve cricket playing acoustic guitar intpish thread ever see would able expression painting stallion life know pick homo drawing background animation working right march felt compel brand mark watneyxs postcard read book get_down brand comedian turtleneck gordon unicorn chime see two first narrative intj recently get_down post comedian two friend turtleneck gordon unicorn chime post material interest attempt include work probably could work together new model expert abrupt explosion laugh upon assorted wyrd material happen curious sense wit curious much hello nah touch everyone think frighten sad true fact absolutely neutral face kitten actually truly like chuck hug well kind already mention sometimes difficult convey complex material dad head capricious compilation shape picture word think  would allow good night everyone evening person morning right night always supplant morning people say good night order meet following day movie amazing thank hope good sleep air anyhow wish good night following night ahead hopefully land good people deserve good well people may wonder issue name subject discovery response helpful anyhow finally person mention still see creaturesfaces maze assorted random form amuse sometimes handy skill bore know commiseration forfeit whole supermarket decide walmart best think large one would great yipy think fire delicious forfeit bean_curd like waste food think godhead thread care departure year heh understand given language yes adventure time get angry quite rarely safe surround people somewhere else impossible hide suppress anger manner get rid feeling explosion never wish anything fake bad actually hug given chosen one chosen quite though yup right course comfortable homo race survive thankfully woman ability give birth homo being work thousand year change besides happen happen frequently people use consequence highly precise elaborate on-line trial footing determine one type ocular language art survey graphic design truly enjoy interest field ability generate idea solve problem much important possession particular alexandra deviantart always ready discipline intimidate precise sibling wrongdoer universe domination shooting people head right intjs always must characterize word privation show badly chemical_reaction istp\n"
     ]
    }
   ],
   "source": [
    "# Load a text file if required\n",
    "text = \"\"\"DAVID good one course say know blessing curse absolutely positive best friend could amazing couple count yes could madly love case reconciled feeling thank link socaled tisi loop stem current topicobsesion deadly like stuck thought mind wanders circle feel truly terrible noticed peculiar vegetation look grass dozen different plant specie imagine hundred year later whenif soil smith never one ever often find spotting face marble tileswod yearold sentence incredibly accurate beautiful description visited website last year whoever read maybe even remembers highly doubt sit garden writing song sing together dozen cricket playing acoustic guitar intpish thread ever seen would able look painting entire life knew picked human drawing background animation working right mar felt obligated make mark watneyxs postcard read book started make comic turtle gordon unicorn chime see two first story intj recently started post comic two friend turtle gordon unicorn chime posted stuff interested try include work probably could work together new model expert abrupt explosion laughter upon various weird stuff happens peculiar sense humor peculiar much hello nah touch everyone think scared sad true fact absolutely neutral face kitten actually really like patting hug well kind already mentioned sometimes hard convey complex stuff pop head whimsical compilation shape picture word think kitten would appropriate good night everyone even someone morning right night always supersede morning people say good night order meet next day movie awesome thank hope good sleep air anyway wishing good night next night ahead hopefully land good people deserve good well people may wondering issue name topic find response helpful anyway finally someone mentioned still see creaturesfaces maze various random pattern amusing sometimes handy skill bored know pity sacrifice whole supermarket decide walmart best think biggest one would great yipy think fire delicious sacrifice tofu like waste food think creator thread care going year heh understand given language yes adventure time get angry quite rarely safer surrounding people somewhere else impossible hide suppress anger way get rid feeling burst never liked anything fake bad actually hug given chosen one chosen quite though yup right course comfortable human race survived thankfully woman ability give birth human being worked thousand year change besides happens occurs often people use result extremely precise elaborate online test basis determining one type visual language art study graphic design really enjoy interesting field ability generate idea solve problem much important possession specific alexandra deviantart always ready discipline intimidate precise sibling offender world domination shooting people head right intjs always must characterised word want show badly reaction istp\"\"\"\n",
    "output = \"\"\n",
    "    # Get the list of words from the entire text\n",
    "words = word_tokenize(text)\n",
    "\n",
    "    # Identify the parts of speech\n",
    "tagged = nltk.pos_tag(words)\n",
    "\n",
    "for i in range(0,len(words)):\n",
    "    replacements = []\n",
    "\n",
    "        # Only replace nouns with nouns, vowels with vowels etc.\n",
    "    for syn in wordnet.synsets(words[i]):\n",
    "\n",
    "            # Do not attempt to replace proper nouns or determiners\n",
    "        if tagged[i][1] == 'NNP' or tagged[i][1] == 'DT':\n",
    "             replacements.append('')\n",
    "\n",
    "            # The tokenizer returns strings like NNP, VBP etc\n",
    "            # but the wordnet synonyms has tags like .n.\n",
    "            # So we extract the first character from NNP ie n\n",
    "            # then we check if the dictionary word has a .n. or not \n",
    "        word_type = tagged[i][1][0].lower()\n",
    "        if syn.name().find(\".\"+word_type+\".\"):\n",
    "                # extract the word only\n",
    "            r = syn.name()[0:syn.name().find(\".\")]\n",
    "            replacements.append(r)\n",
    "\n",
    "    if len(replacements) > 0:\n",
    "            # Choose a random replacement\n",
    "        replacement = replacements[0]\n",
    "        output = output + \" \" + replacement\n",
    "    else:\n",
    "            # If no replacement could be found, then just use the\n",
    "            # original word\n",
    "        output = output + \" \" + words[i]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good one course say know blessing curse absolutely positive best friend could amazing couple count yes could madly love case reconciled feeling thank link socaled tisi loop stem current topicobsesion deadly like stuck thought mind wanders circle feel truly terrible noticed peculiar vegetation look grass dozen different plant specie imagine hundred year later whenif soil smith never one ever often find spotting face marble tileswod yearold sentence incredibly accurate beautiful description visited website last year whoever read maybe even remembers highly doubt sit garden writing song sing together dozen cricket playing acoustic guitar intpish thread ever seen would able look painting entire life knew picked human drawing background animation working right mar felt obligated make mark watneyxs postcard read book started make comic turtle gordon unicorn chime see two first story intj recently started post comic two friend turtle gordon unicorn chime posted stuff interested try include work probably could work together new model expert abrupt explosion laughter upon various weird stuff happens peculiar sense humor peculiar much hello nah touch everyone think scared sad true fact absolutely neutral face kitten actually really like patting hug well kind already mentioned sometimes hard convey complex stuff pop head whimsical compilation shape picture word think kitten would appropriate good night everyone even someone morning right night always supersede morning people say good night order meet next day movie awesome thank hope good sleep air anyway wishing good night next night ahead hopefully land good people deserve good well people may wondering issue name topic find response helpful anyway finally someone mentioned still see creaturesfaces maze various random pattern amusing sometimes handy skill bored know pity sacrifice whole supermarket decide walmart best think biggest one would great yipy think fire delicious sacrifice tofu like waste food think creator thread care going year heh understand given language yes adventure time get angry quite rarely safer surrounding people somewhere else impossible hide suppress anger way get rid feeling burst never liked anything fake bad actually hug given chosen one chosen quite though yup right course comfortable human race survived thankfully woman ability give birth human being worked thousand year change besides happens occurs often people use result extremely precise elaborate online test basis determining one type visual language art study graphic design really enjoy interesting field ability generate idea solve problem much important possession specific alexandra deviantart always ready discipline intimidate precise sibling offender world domination shooting people head right intjs always must characterised word want show badly reaction istp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.tokenize.punkt.PunktSentenceTokenizer at 0x201ba75a358>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Umbrella, Invention, Joy']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DAVID',\n",
       " 'good',\n",
       " 'one',\n",
       " 'course',\n",
       " 'say',\n",
       " 'know',\n",
       " 'blessing',\n",
       " 'curse',\n",
       " 'absolutely',\n",
       " 'positive',\n",
       " 'best',\n",
       " 'friend',\n",
       " 'could',\n",
       " 'amazing',\n",
       " 'couple',\n",
       " 'count',\n",
       " 'yes',\n",
       " 'could',\n",
       " 'madly',\n",
       " 'love',\n",
       " 'case',\n",
       " 'reconciled',\n",
       " 'feeling',\n",
       " 'thank',\n",
       " 'link',\n",
       " 'socaled',\n",
       " 'tisi',\n",
       " 'loop',\n",
       " 'stem',\n",
       " 'current',\n",
       " 'topicobsesion',\n",
       " 'deadly',\n",
       " 'like',\n",
       " 'stuck',\n",
       " 'thought',\n",
       " 'mind',\n",
       " 'wanders',\n",
       " 'circle',\n",
       " 'feel',\n",
       " 'truly',\n",
       " 'terrible',\n",
       " 'noticed',\n",
       " 'peculiar',\n",
       " 'vegetation',\n",
       " 'look',\n",
       " 'grass',\n",
       " 'dozen',\n",
       " 'different',\n",
       " 'plant',\n",
       " 'specie',\n",
       " 'imagine',\n",
       " 'hundred',\n",
       " 'year',\n",
       " 'later',\n",
       " 'whenif',\n",
       " 'soil',\n",
       " 'smith',\n",
       " 'never',\n",
       " 'one',\n",
       " 'ever',\n",
       " 'often',\n",
       " 'find',\n",
       " 'spotting',\n",
       " 'face',\n",
       " 'marble',\n",
       " 'tileswod',\n",
       " 'yearold',\n",
       " 'sentence',\n",
       " 'incredibly',\n",
       " 'accurate',\n",
       " 'beautiful',\n",
       " 'description',\n",
       " 'visited',\n",
       " 'website',\n",
       " 'last',\n",
       " 'year',\n",
       " 'whoever',\n",
       " 'read',\n",
       " 'maybe',\n",
       " 'even',\n",
       " 'remembers',\n",
       " 'highly',\n",
       " 'doubt',\n",
       " 'sit',\n",
       " 'garden',\n",
       " 'writing',\n",
       " 'song',\n",
       " 'sing',\n",
       " 'together',\n",
       " 'dozen',\n",
       " 'cricket',\n",
       " 'playing',\n",
       " 'acoustic',\n",
       " 'guitar',\n",
       " 'intpish',\n",
       " 'thread',\n",
       " 'ever',\n",
       " 'seen',\n",
       " 'would',\n",
       " 'able',\n",
       " 'look',\n",
       " 'painting',\n",
       " 'entire',\n",
       " 'life',\n",
       " 'knew',\n",
       " 'picked',\n",
       " 'human',\n",
       " 'drawing',\n",
       " 'background',\n",
       " 'animation',\n",
       " 'working',\n",
       " 'right',\n",
       " 'mar',\n",
       " 'felt',\n",
       " 'obligated',\n",
       " 'make',\n",
       " 'mark',\n",
       " 'watneyxs',\n",
       " 'postcard',\n",
       " 'read',\n",
       " 'book',\n",
       " 'started',\n",
       " 'make',\n",
       " 'comic',\n",
       " 'turtle',\n",
       " 'gordon',\n",
       " 'unicorn',\n",
       " 'chime',\n",
       " 'see',\n",
       " 'two',\n",
       " 'first',\n",
       " 'story',\n",
       " 'intj',\n",
       " 'recently',\n",
       " 'started',\n",
       " 'post',\n",
       " 'comic',\n",
       " 'two',\n",
       " 'friend',\n",
       " 'turtle',\n",
       " 'gordon',\n",
       " 'unicorn',\n",
       " 'chime',\n",
       " 'posted',\n",
       " 'stuff',\n",
       " 'interested',\n",
       " 'try',\n",
       " 'include',\n",
       " 'work',\n",
       " 'probably',\n",
       " 'could',\n",
       " 'work',\n",
       " 'together',\n",
       " 'new',\n",
       " 'model',\n",
       " 'expert',\n",
       " 'abrupt',\n",
       " 'explosion',\n",
       " 'laughter',\n",
       " 'upon',\n",
       " 'various',\n",
       " 'weird',\n",
       " 'stuff',\n",
       " 'happens',\n",
       " 'peculiar',\n",
       " 'sense',\n",
       " 'humor',\n",
       " 'peculiar',\n",
       " 'much',\n",
       " 'hello',\n",
       " 'nah',\n",
       " 'touch',\n",
       " 'everyone',\n",
       " 'think',\n",
       " 'scared',\n",
       " 'sad',\n",
       " 'true',\n",
       " 'fact',\n",
       " 'absolutely',\n",
       " 'neutral',\n",
       " 'face',\n",
       " 'kitten',\n",
       " 'actually',\n",
       " 'really',\n",
       " 'like',\n",
       " 'patting',\n",
       " 'hug',\n",
       " 'well',\n",
       " 'kind',\n",
       " 'already',\n",
       " 'mentioned',\n",
       " 'sometimes',\n",
       " 'hard',\n",
       " 'convey',\n",
       " 'complex',\n",
       " 'stuff',\n",
       " 'pop',\n",
       " 'head',\n",
       " 'whimsical',\n",
       " 'compilation',\n",
       " 'shape',\n",
       " 'picture',\n",
       " 'word',\n",
       " 'think',\n",
       " 'kitten',\n",
       " 'would',\n",
       " 'appropriate',\n",
       " 'good',\n",
       " 'night',\n",
       " 'everyone',\n",
       " 'even',\n",
       " 'someone',\n",
       " 'morning',\n",
       " 'right',\n",
       " 'night',\n",
       " 'always',\n",
       " 'supersede',\n",
       " 'morning',\n",
       " 'people',\n",
       " 'say',\n",
       " 'good',\n",
       " 'night',\n",
       " 'order',\n",
       " 'meet',\n",
       " 'next',\n",
       " 'day',\n",
       " 'movie',\n",
       " 'awesome',\n",
       " 'thank',\n",
       " 'hope',\n",
       " 'good',\n",
       " 'sleep',\n",
       " 'air',\n",
       " 'anyway',\n",
       " 'wishing',\n",
       " 'good',\n",
       " 'night',\n",
       " 'next',\n",
       " 'night',\n",
       " 'ahead',\n",
       " 'hopefully',\n",
       " 'land',\n",
       " 'good',\n",
       " 'people',\n",
       " 'deserve',\n",
       " 'good',\n",
       " 'well',\n",
       " 'people',\n",
       " 'may',\n",
       " 'wondering',\n",
       " 'issue',\n",
       " 'name',\n",
       " 'topic',\n",
       " 'find',\n",
       " 'response',\n",
       " 'helpful',\n",
       " 'anyway',\n",
       " 'finally',\n",
       " 'someone',\n",
       " 'mentioned',\n",
       " 'still',\n",
       " 'see',\n",
       " 'creaturesfaces',\n",
       " 'maze',\n",
       " 'various',\n",
       " 'random',\n",
       " 'pattern',\n",
       " 'amusing',\n",
       " 'sometimes',\n",
       " 'handy',\n",
       " 'skill',\n",
       " 'bored',\n",
       " 'know',\n",
       " 'pity',\n",
       " 'sacrifice',\n",
       " 'whole',\n",
       " 'supermarket',\n",
       " 'decide',\n",
       " 'walmart',\n",
       " 'best',\n",
       " 'think',\n",
       " 'biggest',\n",
       " 'one',\n",
       " 'would',\n",
       " 'great',\n",
       " 'yipy',\n",
       " 'think',\n",
       " 'fire',\n",
       " 'delicious',\n",
       " 'sacrifice',\n",
       " 'tofu',\n",
       " 'like',\n",
       " 'waste',\n",
       " 'food',\n",
       " 'think',\n",
       " 'creator',\n",
       " 'thread',\n",
       " 'care',\n",
       " 'going',\n",
       " 'year',\n",
       " 'heh',\n",
       " 'understand',\n",
       " 'given',\n",
       " 'language',\n",
       " 'yes',\n",
       " 'adventure',\n",
       " 'time',\n",
       " 'get',\n",
       " 'angry',\n",
       " 'quite',\n",
       " 'rarely',\n",
       " 'safer',\n",
       " 'surrounding',\n",
       " 'people',\n",
       " 'somewhere',\n",
       " 'else',\n",
       " 'impossible',\n",
       " 'hide',\n",
       " 'suppress',\n",
       " 'anger',\n",
       " 'way',\n",
       " 'get',\n",
       " 'rid',\n",
       " 'feeling',\n",
       " 'burst',\n",
       " 'never',\n",
       " 'liked',\n",
       " 'anything',\n",
       " 'fake',\n",
       " 'bad',\n",
       " 'actually',\n",
       " 'hug',\n",
       " 'given',\n",
       " 'chosen',\n",
       " 'one',\n",
       " 'chosen',\n",
       " 'quite',\n",
       " 'though',\n",
       " 'yup',\n",
       " 'right',\n",
       " 'course',\n",
       " 'comfortable',\n",
       " 'human',\n",
       " 'race',\n",
       " 'survived',\n",
       " 'thankfully',\n",
       " 'woman',\n",
       " 'ability',\n",
       " 'give',\n",
       " 'birth',\n",
       " 'human',\n",
       " 'being',\n",
       " 'worked',\n",
       " 'thousand',\n",
       " 'year',\n",
       " 'change',\n",
       " 'besides',\n",
       " 'happens',\n",
       " 'occurs',\n",
       " 'often',\n",
       " 'people',\n",
       " 'use',\n",
       " 'result',\n",
       " 'extremely',\n",
       " 'precise',\n",
       " 'elaborate',\n",
       " 'online',\n",
       " 'test',\n",
       " 'basis',\n",
       " 'determining',\n",
       " 'one',\n",
       " 'type',\n",
       " 'visual',\n",
       " 'language',\n",
       " 'art',\n",
       " 'study',\n",
       " 'graphic',\n",
       " 'design',\n",
       " 'really',\n",
       " 'enjoy',\n",
       " 'interesting',\n",
       " 'field',\n",
       " 'ability',\n",
       " 'generate',\n",
       " 'idea',\n",
       " 'solve',\n",
       " 'problem',\n",
       " 'much',\n",
       " 'important',\n",
       " 'possession',\n",
       " 'specific',\n",
       " 'alexandra',\n",
       " 'deviantart',\n",
       " 'always',\n",
       " 'ready',\n",
       " 'discipline',\n",
       " 'intimidate',\n",
       " 'precise',\n",
       " 'sibling',\n",
       " 'offender',\n",
       " 'world',\n",
       " 'domination',\n",
       " 'shooting',\n",
       " 'people',\n",
       " 'head',\n",
       " 'right',\n",
       " 'intjs',\n",
       " 'always',\n",
       " 'must',\n",
       " 'characterised',\n",
       " 'word',\n",
       " 'want',\n",
       " 'show',\n",
       " 'badly',\n",
       " 'reaction',\n",
       " 'istp']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DAVID', 'NNP'),\n",
       " ('good', 'JJ'),\n",
       " ('one', 'CD'),\n",
       " ('course', 'NN'),\n",
       " ('say', 'VBP'),\n",
       " ('know', 'VBP'),\n",
       " ('blessing', 'VBG'),\n",
       " ('curse', 'NN'),\n",
       " ('absolutely', 'RB'),\n",
       " ('positive', 'JJ'),\n",
       " ('best', 'JJS'),\n",
       " ('friend', 'NN'),\n",
       " ('could', 'MD'),\n",
       " ('amazing', 'VB'),\n",
       " ('couple', 'JJ'),\n",
       " ('count', 'NN'),\n",
       " ('yes', 'NNS'),\n",
       " ('could', 'MD'),\n",
       " ('madly', 'RB'),\n",
       " ('love', 'VB'),\n",
       " ('case', 'NN'),\n",
       " ('reconciled', 'VBD'),\n",
       " ('feeling', 'VBG'),\n",
       " ('thank', 'NN'),\n",
       " ('link', 'NN'),\n",
       " ('socaled', 'VBD'),\n",
       " ('tisi', 'JJ'),\n",
       " ('loop', 'JJ'),\n",
       " ('stem', 'NN'),\n",
       " ('current', 'JJ'),\n",
       " ('topicobsesion', 'NN'),\n",
       " ('deadly', 'RB'),\n",
       " ('like', 'IN'),\n",
       " ('stuck', 'VBN'),\n",
       " ('thought', 'VBN'),\n",
       " ('mind', 'NN'),\n",
       " ('wanders', 'NNS'),\n",
       " ('circle', 'VBP'),\n",
       " ('feel', 'VB'),\n",
       " ('truly', 'RB'),\n",
       " ('terrible', 'JJ'),\n",
       " ('noticed', 'JJ'),\n",
       " ('peculiar', 'JJ'),\n",
       " ('vegetation', 'NN'),\n",
       " ('look', 'NN'),\n",
       " ('grass', 'VBP'),\n",
       " ('dozen', 'NN'),\n",
       " ('different', 'JJ'),\n",
       " ('plant', 'NN'),\n",
       " ('specie', 'NN'),\n",
       " ('imagine', 'NN'),\n",
       " ('hundred', 'CD'),\n",
       " ('year', 'NN'),\n",
       " ('later', 'RB'),\n",
       " ('whenif', 'JJ'),\n",
       " ('soil', 'NN'),\n",
       " ('smith', 'NN'),\n",
       " ('never', 'RB'),\n",
       " ('one', 'CD'),\n",
       " ('ever', 'RB'),\n",
       " ('often', 'RB'),\n",
       " ('find', 'VBP'),\n",
       " ('spotting', 'VBG'),\n",
       " ('face', 'NN'),\n",
       " ('marble', 'JJ'),\n",
       " ('tileswod', 'NN'),\n",
       " ('yearold', 'JJ'),\n",
       " ('sentence', 'NN'),\n",
       " ('incredibly', 'RB'),\n",
       " ('accurate', 'JJ'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('description', 'NN'),\n",
       " ('visited', 'VBD'),\n",
       " ('website', 'NN'),\n",
       " ('last', 'JJ'),\n",
       " ('year', 'NN'),\n",
       " ('whoever', 'RB'),\n",
       " ('read', 'VBD'),\n",
       " ('maybe', 'RB'),\n",
       " ('even', 'RB'),\n",
       " ('remembers', 'NNS'),\n",
       " ('highly', 'RB'),\n",
       " ('doubt', 'VBP'),\n",
       " ('sit', 'VB'),\n",
       " ('garden', 'NN'),\n",
       " ('writing', 'NN'),\n",
       " ('song', 'NN'),\n",
       " ('sing', 'VBG'),\n",
       " ('together', 'RB'),\n",
       " ('dozen', 'NN'),\n",
       " ('cricket', 'NN'),\n",
       " ('playing', 'VBG'),\n",
       " ('acoustic', 'JJ'),\n",
       " ('guitar', 'NN'),\n",
       " ('intpish', 'JJ'),\n",
       " ('thread', 'NN'),\n",
       " ('ever', 'RB'),\n",
       " ('seen', 'VBN'),\n",
       " ('would', 'MD'),\n",
       " ('able', 'JJ'),\n",
       " ('look', 'VB'),\n",
       " ('painting', 'VBG'),\n",
       " ('entire', 'JJ'),\n",
       " ('life', 'NN'),\n",
       " ('knew', 'VBD'),\n",
       " ('picked', 'JJ'),\n",
       " ('human', 'JJ'),\n",
       " ('drawing', 'VBG'),\n",
       " ('background', 'NN'),\n",
       " ('animation', 'NN'),\n",
       " ('working', 'VBG'),\n",
       " ('right', 'JJ'),\n",
       " ('mar', 'NN'),\n",
       " ('felt', 'VBD'),\n",
       " ('obligated', 'JJ'),\n",
       " ('make', 'NN'),\n",
       " ('mark', 'NN'),\n",
       " ('watneyxs', 'JJ'),\n",
       " ('postcard', 'NN'),\n",
       " ('read', 'VBD'),\n",
       " ('book', 'NN'),\n",
       " ('started', 'VBD'),\n",
       " ('make', 'VBP'),\n",
       " ('comic', 'JJ'),\n",
       " ('turtle', 'NN'),\n",
       " ('gordon', 'NN'),\n",
       " ('unicorn', 'JJ'),\n",
       " ('chime', 'NN'),\n",
       " ('see', 'VB'),\n",
       " ('two', 'CD'),\n",
       " ('first', 'JJ'),\n",
       " ('story', 'NN'),\n",
       " ('intj', 'NN'),\n",
       " ('recently', 'RB'),\n",
       " ('started', 'VBD'),\n",
       " ('post', 'NN'),\n",
       " ('comic', 'JJ'),\n",
       " ('two', 'CD'),\n",
       " ('friend', 'VBP'),\n",
       " ('turtle', 'JJ'),\n",
       " ('gordon', 'JJ'),\n",
       " ('unicorn', 'JJ'),\n",
       " ('chime', 'NN'),\n",
       " ('posted', 'VBD'),\n",
       " ('stuff', 'NN'),\n",
       " ('interested', 'JJ'),\n",
       " ('try', 'NN'),\n",
       " ('include', 'VBP'),\n",
       " ('work', 'NN'),\n",
       " ('probably', 'RB'),\n",
       " ('could', 'MD'),\n",
       " ('work', 'VB'),\n",
       " ('together', 'RB'),\n",
       " ('new', 'JJ'),\n",
       " ('model', 'NN'),\n",
       " ('expert', 'NN'),\n",
       " ('abrupt', 'JJ'),\n",
       " ('explosion', 'NN'),\n",
       " ('laughter', 'RBR'),\n",
       " ('upon', 'IN'),\n",
       " ('various', 'JJ'),\n",
       " ('weird', 'JJ'),\n",
       " ('stuff', 'NN'),\n",
       " ('happens', 'VBZ'),\n",
       " ('peculiar', 'JJ'),\n",
       " ('sense', 'NN'),\n",
       " ('humor', 'NN'),\n",
       " ('peculiar', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('hello', 'NN'),\n",
       " ('nah', 'RB'),\n",
       " ('touch', 'JJ'),\n",
       " ('everyone', 'NN'),\n",
       " ('think', 'NN'),\n",
       " ('scared', 'VBD'),\n",
       " ('sad', 'JJ'),\n",
       " ('true', 'JJ'),\n",
       " ('fact', 'NN'),\n",
       " ('absolutely', 'RB'),\n",
       " ('neutral', 'JJ'),\n",
       " ('face', 'NN'),\n",
       " ('kitten', 'VBN'),\n",
       " ('actually', 'RB'),\n",
       " ('really', 'RB'),\n",
       " ('like', 'IN'),\n",
       " ('patting', 'VBG'),\n",
       " ('hug', 'RB'),\n",
       " ('well', 'RB'),\n",
       " ('kind', 'NN'),\n",
       " ('already', 'RB'),\n",
       " ('mentioned', 'VBN'),\n",
       " ('sometimes', 'RB'),\n",
       " ('hard', 'JJ'),\n",
       " ('convey', 'NN'),\n",
       " ('complex', 'JJ'),\n",
       " ('stuff', 'NN'),\n",
       " ('pop', 'NN'),\n",
       " ('head', 'NN'),\n",
       " ('whimsical', 'JJ'),\n",
       " ('compilation', 'NN'),\n",
       " ('shape', 'NN'),\n",
       " ('picture', 'NN'),\n",
       " ('word', 'NN'),\n",
       " ('think', 'NN'),\n",
       " ('kitten', 'NNP'),\n",
       " ('would', 'MD'),\n",
       " ('appropriate', 'VB'),\n",
       " ('good', 'JJ'),\n",
       " ('night', 'NN'),\n",
       " ('everyone', 'NN'),\n",
       " ('even', 'RB'),\n",
       " ('someone', 'NN'),\n",
       " ('morning', 'NN'),\n",
       " ('right', 'JJ'),\n",
       " ('night', 'NN'),\n",
       " ('always', 'RB'),\n",
       " ('supersede', 'VB'),\n",
       " ('morning', 'NN'),\n",
       " ('people', 'NNS'),\n",
       " ('say', 'VBP'),\n",
       " ('good', 'JJ'),\n",
       " ('night', 'NN'),\n",
       " ('order', 'NN'),\n",
       " ('meet', 'NN'),\n",
       " ('next', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('movie', 'NN'),\n",
       " ('awesome', 'JJ'),\n",
       " ('thank', 'NN'),\n",
       " ('hope', 'NN'),\n",
       " ('good', 'JJ'),\n",
       " ('sleep', 'NN'),\n",
       " ('air', 'NN'),\n",
       " ('anyway', 'RB'),\n",
       " ('wishing', 'VBG'),\n",
       " ('good', 'JJ'),\n",
       " ('night', 'NN'),\n",
       " ('next', 'JJ'),\n",
       " ('night', 'NN'),\n",
       " ('ahead', 'RB'),\n",
       " ('hopefully', 'RB'),\n",
       " ('land', 'VBP'),\n",
       " ('good', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('deserve', 'VBP'),\n",
       " ('good', 'JJ'),\n",
       " ('well', 'RB'),\n",
       " ('people', 'NNS'),\n",
       " ('may', 'MD'),\n",
       " ('wondering', 'VBG'),\n",
       " ('issue', 'NN'),\n",
       " ('name', 'NN'),\n",
       " ('topic', 'VBD'),\n",
       " ('find', 'JJ'),\n",
       " ('response', 'NN'),\n",
       " ('helpful', 'JJ'),\n",
       " ('anyway', 'RB'),\n",
       " ('finally', 'RB'),\n",
       " ('someone', 'NN'),\n",
       " ('mentioned', 'VBD'),\n",
       " ('still', 'RB'),\n",
       " ('see', 'VB'),\n",
       " ('creaturesfaces', 'NNS'),\n",
       " ('maze', 'VBP'),\n",
       " ('various', 'JJ'),\n",
       " ('random', 'JJ'),\n",
       " ('pattern', 'NN'),\n",
       " ('amusing', 'VBG'),\n",
       " ('sometimes', 'RB'),\n",
       " ('handy', 'JJ'),\n",
       " ('skill', 'NN'),\n",
       " ('bored', 'VBD'),\n",
       " ('know', 'JJ'),\n",
       " ('pity', 'NN'),\n",
       " ('sacrifice', 'NN'),\n",
       " ('whole', 'JJ'),\n",
       " ('supermarket', 'NN'),\n",
       " ('decide', 'VB'),\n",
       " ('walmart', 'JJ'),\n",
       " ('best', 'JJS'),\n",
       " ('think', 'NN'),\n",
       " ('biggest', 'JJS'),\n",
       " ('one', 'CD'),\n",
       " ('would', 'MD'),\n",
       " ('great', 'JJ'),\n",
       " ('yipy', 'JJ'),\n",
       " ('think', 'VBP'),\n",
       " ('fire', 'VBP'),\n",
       " ('delicious', 'JJ'),\n",
       " ('sacrifice', 'NN'),\n",
       " ('tofu', 'NN'),\n",
       " ('like', 'IN'),\n",
       " ('waste', 'NN'),\n",
       " ('food', 'NN'),\n",
       " ('think', 'VBP'),\n",
       " ('creator', 'NN'),\n",
       " ('thread', 'NN'),\n",
       " ('care', 'NN'),\n",
       " ('going', 'VBG'),\n",
       " ('year', 'NN'),\n",
       " ('heh', 'NN'),\n",
       " ('understand', 'VB'),\n",
       " ('given', 'VBN'),\n",
       " ('language', 'NN'),\n",
       " ('yes', 'RB'),\n",
       " ('adventure', 'JJ'),\n",
       " ('time', 'NN'),\n",
       " ('get', 'VB'),\n",
       " ('angry', 'JJ'),\n",
       " ('quite', 'RB'),\n",
       " ('rarely', 'RB'),\n",
       " ('safer', 'VB'),\n",
       " ('surrounding', 'VBG'),\n",
       " ('people', 'NNS'),\n",
       " ('somewhere', 'RB'),\n",
       " ('else', 'RB'),\n",
       " ('impossible', 'JJ'),\n",
       " ('hide', 'NN'),\n",
       " ('suppress', 'NN'),\n",
       " ('anger', 'NN'),\n",
       " ('way', 'NN'),\n",
       " ('get', 'VBP'),\n",
       " ('rid', 'JJ'),\n",
       " ('feeling', 'NN'),\n",
       " ('burst', 'NN'),\n",
       " ('never', 'RB'),\n",
       " ('liked', 'VBD'),\n",
       " ('anything', 'NN'),\n",
       " ('fake', 'JJ'),\n",
       " ('bad', 'JJ'),\n",
       " ('actually', 'RB'),\n",
       " ('hug', 'JJ'),\n",
       " ('given', 'VBN'),\n",
       " ('chosen', 'VBP'),\n",
       " ('one', 'CD'),\n",
       " ('chosen', 'NN'),\n",
       " ('quite', 'RB'),\n",
       " ('though', 'IN'),\n",
       " ('yup', 'RB'),\n",
       " ('right', 'JJ'),\n",
       " ('course', 'NN'),\n",
       " ('comfortable', 'JJ'),\n",
       " ('human', 'JJ'),\n",
       " ('race', 'NN'),\n",
       " ('survived', 'VBD'),\n",
       " ('thankfully', 'RB'),\n",
       " ('woman', 'NN'),\n",
       " ('ability', 'NN'),\n",
       " ('give', 'VBP'),\n",
       " ('birth', 'NN'),\n",
       " ('human', 'JJ'),\n",
       " ('being', 'VBG'),\n",
       " ('worked', 'VBN'),\n",
       " ('thousand', 'CD'),\n",
       " ('year', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('besides', 'IN'),\n",
       " ('happens', 'NNS'),\n",
       " ('occurs', 'NNS'),\n",
       " ('often', 'RB'),\n",
       " ('people', 'NNS'),\n",
       " ('use', 'VBP'),\n",
       " ('result', 'NN'),\n",
       " ('extremely', 'RB'),\n",
       " ('precise', 'JJ'),\n",
       " ('elaborate', 'JJ'),\n",
       " ('online', 'NN'),\n",
       " ('test', 'NN'),\n",
       " ('basis', 'NN'),\n",
       " ('determining', 'VBG'),\n",
       " ('one', 'CD'),\n",
       " ('type', 'NN'),\n",
       " ('visual', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('art', 'NN'),\n",
       " ('study', 'NN'),\n",
       " ('graphic', 'JJ'),\n",
       " ('design', 'NN'),\n",
       " ('really', 'RB'),\n",
       " ('enjoy', 'VB'),\n",
       " ('interesting', 'JJ'),\n",
       " ('field', 'NN'),\n",
       " ('ability', 'NN'),\n",
       " ('generate', 'VBP'),\n",
       " ('idea', 'NN'),\n",
       " ('solve', 'NN'),\n",
       " ('problem', 'NN'),\n",
       " ('much', 'JJ'),\n",
       " ('important', 'JJ'),\n",
       " ('possession', 'NN'),\n",
       " ('specific', 'JJ'),\n",
       " ('alexandra', 'JJ'),\n",
       " ('deviantart', 'NN'),\n",
       " ('always', 'RB'),\n",
       " ('ready', 'JJ'),\n",
       " ('discipline', 'NN'),\n",
       " ('intimidate', 'NN'),\n",
       " ('precise', 'NN'),\n",
       " ('sibling', 'VBG'),\n",
       " ('offender', 'JJR'),\n",
       " ('world', 'NN'),\n",
       " ('domination', 'NN'),\n",
       " ('shooting', 'VBG'),\n",
       " ('people', 'NNS'),\n",
       " ('head', 'VBP'),\n",
       " ('right', 'JJ'),\n",
       " ('intjs', 'NN'),\n",
       " ('always', 'RB'),\n",
       " ('must', 'MD'),\n",
       " ('characterised', 'VBN'),\n",
       " ('word', 'NN'),\n",
       " ('want', 'NN'),\n",
       " ('show', 'NN'),\n",
       " ('badly', 'RB'),\n",
       " ('reaction', 'NN'),\n",
       " ('istp', 'NN')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynReplace(object) :\n",
    "    def __init__(self):\n",
    "        self.text = ''\n",
    "    def replace(self ,text):\n",
    "                # Get the list of words from the entire text\n",
    "        words = word_tokenize(text)\n",
    "\n",
    "            # Identify the parts of speech\n",
    "        tagged = nltk.pos_tag(words)\n",
    "\n",
    "        for i in range(0,len(words)):\n",
    "            replacements = []\n",
    "\n",
    "                # Only replace nouns with nouns, vowels with vowels etc.\n",
    "            for syn in wordnet.synsets(words[i]):\n",
    "\n",
    "                    # Do not attempt to replace proper nouns or determiners\n",
    "                if tagged[i][1] == 'NNP' or tagged[i][1] == 'DT':\n",
    "                     replacements.append('')\n",
    "\n",
    "                    # The tokenizer returns strings like NNP, VBP etc\n",
    "                    # but the wordnet synonyms has tags like .n.\n",
    "                    # So we extract the first character from NNP ie n\n",
    "                    # then we check if the dictionary word has a .n. or not \n",
    "                word_type = tagged[i][1][0].lower()\n",
    "                if syn.name().find(\".\"+word_type+\".\"):\n",
    "                        # extract the word only\n",
    "                    r = syn.name()[0:syn.name().find(\".\")]\n",
    "                    replacements.append(r)\n",
    "\n",
    "            if len(replacements) > 0:\n",
    "                    # Choose a random replacement\n",
    "                replacement = replacements[0]\n",
    "                words[i] = replacement\n",
    "        return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynReplace1(object) :\n",
    "    def __init__(self):\n",
    "        self.text = ''\n",
    "    def replace(self ,text):\n",
    "                # Get the list of words from the entire text\n",
    "        words = word_tokenize(text)\n",
    "\n",
    "            # Identify the parts of speech\n",
    "        tagged = nltk.pos_tag(words)\n",
    "\n",
    "        for i in range(0,len(words)):\n",
    "            #replacements = []\n",
    "\n",
    "                # Only replace nouns with nouns, vowels with vowels etc.\n",
    "#             for syn in wordnet.synsets(words[i]):\n",
    "\n",
    "                    # Do not attempt to replace proper nouns or determiners\n",
    "#                 if tagged[i][1] == 'NNP' or tagged[i][1] == 'DT':\n",
    "#                      replacements.append('')\n",
    "\n",
    "                    # The tokenizer returns strings like NNP, VBP etc\n",
    "                    # but the wordnet synonyms has tags like .n.\n",
    "                    # So we extract the first character from NNP ie n\n",
    "                    # then we check if the dictionary word has a .n. or not \n",
    "#                 word_type = tagged[i][1][0].lower()\n",
    "            syn = wordnet.synsets(words[i])\n",
    "            if len(syn)>0:\n",
    "                a = syn[0].hypernyms()\n",
    "                if len(a)>0:\n",
    "                    words[i] = a[0].name()[:a[0].name().find(\".\")]\n",
    "#             if len(replacements) > 0:\n",
    "#                     # Choose a random replacement\n",
    "#                 replacement = replacements[0]\n",
    "#                 words[i] = replacement\n",
    "        return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SynReplace1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'David naughty male .'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.replace(\"David naughty boy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('walk.n.01'),\n",
       " Synset('base_on_balls.n.01'),\n",
       " Synset('walk.n.03'),\n",
       " Synset('walk.n.04'),\n",
       " Synset('walk.n.05'),\n",
       " Synset('walk.n.06'),\n",
       " Synset('walk_of_life.n.01'),\n",
       " Synset('walk.v.01'),\n",
       " Synset('walk.v.02'),\n",
       " Synset('walk.v.03'),\n",
       " Synset('walk.v.04'),\n",
       " Synset('walk.v.05'),\n",
       " Synset('walk.v.06'),\n",
       " Synset('walk.v.07'),\n",
       " Synset('walk.v.08'),\n",
       " Synset('walk.v.09'),\n",
       " Synset('walk.v.10')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets(\"walk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fruit_tree\n",
      "edible_fruit\n",
      "pink\n"
     ]
    }
   ],
   "source": [
    "syn = wordnet.synsets('apricot')\n",
    "# for synonymn in syn:\n",
    "#     print (\"\\nSynset name :  \", synonymn.name()) \n",
    "#     print (\"Synset abstract term :  \", synonymn.hypernyms()) \n",
    "#print (\"Synset root hypernerm :  \", syn.root_hypernyms()) \n",
    "for j in syn:\n",
    "    for i in j.hypernyms():\n",
    "        print(i.name()[0:i.name().find(\".\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fruit_tree'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = syn[0].hypernyms()\n",
    "a[0].name()[:a[0].name().find(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('fruit_tree.n.01')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fruit_tree'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].name()[:a[0].name().find(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
